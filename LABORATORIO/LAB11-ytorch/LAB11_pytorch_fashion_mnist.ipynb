{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LAB11-pytorch-fashion_mnist.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "F_XbWYaCz04h"
      },
      "outputs": [],
      "source": [
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "fashion_train= '/content/drive/MyDrive/SIS420-INTELIGENCIA_ARTIFICIAL/DATASETs/fashion-mnist_train.csv'\n",
        "data_train = np.loadtxt(fashion_train, skiprows=1, delimiter=',')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P6xD84kx0CEH",
        "outputId": "1653f42f-b0e3-4633-e70f-3c11809e1e83"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X, Y = data_train[:,1:], data_train[:,0]"
      ],
      "metadata": {
        "id": "iXgrCH_dT47n"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fashin_test = '/content/drive/MyDrive/SIS420-INTELIGENCIA_ARTIFICIAL/DATASETs/fashion-mnist_test.csv'\n",
        "data_test = np.loadtxt(fashin_test, skiprows=1, delimiter=',')\n",
        "x_test, y_test =  data_test[:,1:], data_test[:,0]"
      ],
      "metadata": {
        "id": "BIpLw_COTBPJ"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# normalización y split\n",
        "X_train = X[:] / 255\n",
        "X_test = x_test[:] / 255\n",
        "y_train = Y[:].astype(np.int)\n",
        "y_test = y_test[:].astype(np.int)\n",
        "# X_train, X_test, y_train, y_test = X[:50000] / 255., x_test[50000:] / 255., Y[:50000].astype(np.int), y_test[50000:].astype(np.int)"
      ],
      "metadata": {
        "id": "3AiTFvcv0Xf5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "445e308a-ac00-43c3-ee44-d02405a57b03"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  after removing the cwd from sys.path.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  \"\"\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "D_in, H, D_out = 784, 100, 10\n",
        "\n",
        "# convertimos datos a tensores y copiamos en gpu\n",
        "X_t = torch.from_numpy(X_train).float().cuda()\n",
        "Y_t = torch.from_numpy(y_train).long().cuda()\n",
        "\n",
        "model = torch.nn.Sequential(\n",
        "    torch.nn.Linear(D_in, H),\n",
        "    torch.nn.ReLU(),\n",
        "    torch.nn.Linear(H, D_out),\n",
        ")#.to(\"cuda\")\n"
      ],
      "metadata": {
        "id": "lpYBOID7h-n6"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "outputs = model(torch.randn(64, 784))\n",
        "outputs.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aTBIgsP3XmDo",
        "outputId": "d43674f1-cb53-493d-cf60-af217715fa24"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([64, 10])"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.to(\"cuda\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QZnhuS9nYNbC",
        "outputId": "e25503de-021b-41b2-b9ed-1c1c96f9ebde"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sequential(\n",
              "  (0): Linear(in_features=784, out_features=100, bias=True)\n",
              "  (1): ReLU()\n",
              "  (2): Linear(in_features=100, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "t_yItAlcYNZp"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# función de pérdida y derivada\n",
        "\n",
        "def softmax(x):\n",
        "    return torch.exp(x) / torch.exp(x).sum(axis=-1,keepdims=True)\n",
        "\n",
        "# def cross_entropy(output, target):\n",
        "#     logits = output[torch.arange(len(output)), target]\n",
        "#     loss = - logits + torch.log(torch.sum(torch.exp(output), axis=-1))\n",
        "#     loss = loss.mean()\n",
        "#     return loss"
      ],
      "metadata": {
        "id": "2f7CIEkq10au"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "def evaluate(x):\n",
        "    model.eval()\n",
        "    y_pred = model(x)\n",
        "    y_probas = softmax(y_pred)\n",
        "    return torch.argmax(y_probas, axis=1)\n",
        "\n",
        "y_pred = evaluate(torch.from_numpy(X_test).float().cuda())\n",
        "accuracy_score(y_test, y_pred.cpu().numpy())"
      ],
      "metadata": {
        "id": "ErryDl7t1gFs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "73515d92-221f-49fb-bfa1-34da68e48394"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0645"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "criterion = torch.nn.CrossEntropyLoss() # funcion de perdida\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.8) # optimizador desenso por el gradiente\n",
        "\n",
        "epochs = 100\n",
        "log_each = 10\n",
        "l = []\n",
        "model.train()\n",
        "for e in range(1, epochs+1): \n",
        "    \n",
        "    # forward\n",
        "    y_pred = model(X_t)\n",
        "\n",
        "    # loss\n",
        "    loss = criterion(y_pred, Y_t)\n",
        "    l.append(loss.item())\n",
        "    \n",
        "    # ponemos a cero los gradientes\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # Backprop (calculamos todos los gradientes automáticamente)\n",
        "    loss.backward()\n",
        "\n",
        "    # update de los pesos\n",
        "    optimizer.step()\n",
        "    \n",
        "    if not e % log_each:\n",
        "        print(f\"Epoch {e}/{epochs} Loss {np.mean(l):.5f}\")\n",
        "        \n",
        "y_pred = evaluate(torch.from_numpy(X_test).float().cuda())\n",
        "accuracy_score(y_test, y_pred.cpu().numpy())"
      ],
      "metadata": {
        "id": "BRReqID60dAD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c98d118c-c30b-4b27-f84e-d29adef4a877"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10/100 Loss 0.40754\n",
            "Epoch 20/100 Loss 0.40469\n",
            "Epoch 30/100 Loss 0.40917\n",
            "Epoch 40/100 Loss 0.40793\n",
            "Epoch 50/100 Loss 0.40803\n",
            "Epoch 60/100 Loss 0.40768\n",
            "Epoch 70/100 Loss 0.40605\n",
            "Epoch 80/100 Loss 0.40605\n",
            "Epoch 90/100 Loss 0.40606\n",
            "Epoch 100/100 Loss 0.40576\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8553"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    }
  ]
}